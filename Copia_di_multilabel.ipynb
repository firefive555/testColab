{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/firefive555/testColab/blob/main/Copia_di_multilabel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install matplot\n",
        "!pip install torch\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install accelerate\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "2syLGHH_t1wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LXA4v5KMfyN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nuova sezione"
      ],
      "metadata": {
        "id": "QTVv_QsuwR-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wl9CSq3OTGsi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModel,AutoModelForSequenceClassification, BertForSequenceClassification, TrainingArguments, Trainer\n",
        "import torch\n",
        "from transformers import pipeline, EvalPrediction\n",
        "from datasets import load_dataset, load_metric\n",
        "import evaluate\n",
        "from accelerate.utils import write_basic_config\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "import optuna\n",
        "write_basic_config(mixed_precision='fp16', )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Musixmatch/umberto-wikipedia-uncased-v1\")\n"
      ],
      "metadata": {
        "id": "vS6hfsVcTn9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes = [\"Anger\", \"Joy\" , \"Disgust\" , \"Neutral\" , \"Surprise\" , \"Sadness\" , \"Fear\" , \"Trust\" , \"Anticipation\" , \"Love\"]"
      ],
      "metadata": {
        "id": "kwsWlw3G_utx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = (load_dataset('csv' , data_files=\"/content/emit_train_A.csv\", split='train').train_test_split(test_size=0.2 , seed=0))\n"
      ],
      "metadata": {
        "id": "--QtlksX0yse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [label for label in dataset['train'].features.keys() if label not in ['text' , 'id']]\n",
        "id2label = {idx:label for idx, label in enumerate(labels)}\n",
        "label2id = {label:idx for idx, label in enumerate(labels)}\n",
        "labels"
      ],
      "metadata": {
        "id": "JTPgebCx1IM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(examples):\n",
        "  # take a batch of texts\n",
        "  text = examples[\"text\"]\n",
        "  # encode them\n",
        "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
        "  # add labels\n",
        "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
        "  # create numpy array of shape (batch_size, num_labels)\n",
        "  labels_matrix = np.zeros((len(text), len(labels)))\n",
        "  # fill numpy array\n",
        "  for idx, label in enumerate(labels):\n",
        "    labels_matrix[:, idx] = labels_batch[label]\n",
        "\n",
        "  encoding[\"labels\"] = labels_matrix.tolist()\n",
        "\n",
        "  return encoding"
      ],
      "metadata": {
        "id": "fXYBWiCl1oG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
      ],
      "metadata": {
        "id": "TiD7z8eQmgXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "eH4hff6WnVWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    # return as dictionary\n",
        "    metrics = {'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'accuracy': accuracy}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions,\n",
        "            tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "hCnDt5xe3MaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 32\n",
        "metric_name = \"f1\""
      ],
      "metadata": {
        "id": "6tdj2IY03FXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  epoch = trial.suggest_loguniform(\"epoch\" , 1 , 15)\n",
        "  learning = trial.suggest_loguniform(\"learning_rate\" , 5e-6 , 5e-4)\n",
        "\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\"Musixmatch/umberto-wikipedia-uncased-v1\",\n",
        "                                                           problem_type=\"multi_label_classification\",\n",
        "                                                           num_labels=len(labels),\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id)\n",
        "  model.to(\"cpu\")\n",
        "  arg = TrainingArguments(\n",
        "      f\"bert-finetuned-sem_eval-english\",\n",
        "      evaluation_strategy = \"epoch\",\n",
        "      save_strategy = \"epoch\",\n",
        "      learning_rate=learning,\n",
        "      per_device_train_batch_size=batch,\n",
        "      per_device_eval_batch_size=batch,\n",
        "      num_train_epochs=epoch,\n",
        "      weight_decay=0.01,\n",
        "      load_best_model_at_end=True,\n",
        "      metric_for_best_model=metric_name,\n",
        "      #push_to_hub=True,\n",
        "  )\n",
        "  trainer = Trainer(\n",
        "      model = model,\n",
        "      args = arg,\n",
        "      train_dataset=encoded_dataset[\"train\"],\n",
        "      eval_dataset=encoded_dataset[\"test\"],\n",
        "      tokenizer=tokenizer,\n",
        "      compute_metrics=compute_metrics\n",
        "  )\n",
        "  trainer.train()\n",
        "  evaluation = trainer.evaluate()\n",
        "  return evaluation[\"eval_f1\"]\n"
      ],
      "metadata": {
        "id": "dDDDwVt_ZXIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials = 100)"
      ],
      "metadata": {
        "id": "K09JA0y9a2AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = study.best_params"
      ],
      "metadata": {
        "id": "j0chaXB0bvEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d8uzws6b1Ot",
        "outputId": "36f5a9a1-98da-45ab-b948-12b2b27f23a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 6.106632873269415, 'learning_rate': 2.980729613776038e-05}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7WXED1Hf3vbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nuova sezione"
      ],
      "metadata": {
        "id": "3u-Lm7JTmIum"
      }
    }
  ]
}